{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import codecs#to convert utf-8 to latin2\n",
    "import random\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC,LinearSVC,NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self,*classifiers):\n",
    "        self._classifiers=classifiers\n",
    "    \n",
    "    def classify(self,features):\n",
    "        votes=[]\n",
    "        for c in self._classifiers:\n",
    "            v=c.classify(features)\n",
    "            votes.append(v)\n",
    "        \n",
    "        #print(votes)\n",
    "        return mode(votes)\n",
    "    def confidence(self,features):\n",
    "        votes=[]\n",
    "        for c in self._classifiers:\n",
    "            v=c.classify(features)\n",
    "            votes.append(v)\n",
    "            \n",
    "        choice_votes=votes.count(mode(votes))\n",
    "        print(choice_votes)\n",
    "        conf=choice_votes/len(votes)\n",
    "        \n",
    "        return conf\n",
    "short_pos = codecs.open(\"positive.txt\",\"r\", encoding='latin2').read()\n",
    "short_neg = codecs.open(\"negative.txt\",\"r\", encoding='latin2').read()\n",
    "#short_pos=open(\"positive.txt\",\"r\").read()\n",
    "#short_neg=open(\"negative.txt\",\"r\").read()\n",
    "\n",
    "documents=[]\n",
    "\n",
    "for review in short_pos.split('\\n'):\n",
    "    documents.append((review,\"pos\"))\n",
    "for review in short_pos.split('\\n'):\n",
    "    documents.append((review,\"neg\"))\n",
    "\n",
    "all_words=[]\n",
    "\n",
    "short_words_pos=word_tokenize(short_pos)\n",
    "short_words_neg=word_tokenize(short_neg)\n",
    "\n",
    "for w in short_words_pos:\n",
    "    all_words.append(w.lower())\n",
    "    \n",
    "for w in short_words_neg:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "\n",
    "all_words=nltk.FreqDist(all_words)\n",
    "\n",
    "word_features=list(all_words.keys())[:5000]\n",
    "\n",
    "def find_features(document):\n",
    "    words=word_tokenize(document)\n",
    "    features={}\n",
    "    for w in word_features:\n",
    "        features[w]= (w in words)\n",
    "    \n",
    "    return features\n",
    "    \n",
    "featuresets=[(find_features(rev),category) for (rev,category) in documents]\n",
    "\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "training_set=featuresets[:10000]\n",
    "test_set=featuresets[10000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_accuracy by naive_bayes: 14.006024096385541\n",
      "Most Informative Features\n",
      "                 passing = True              pos : neg    =      2.3 : 1.0\n",
      "              transition = True              pos : neg    =      2.3 : 1.0\n",
      "             desperately = True              pos : neg    =      2.3 : 1.0\n",
      "                historia = True              pos : neg    =      2.3 : 1.0\n",
      "               palatable = True              neg : pos    =      2.3 : 1.0\n",
      "                  cletis = True              neg : pos    =      2.3 : 1.0\n",
      "                graceful = True              neg : pos    =      2.3 : 1.0\n",
      "                   dumas = True              neg : pos    =      2.2 : 1.0\n",
      "                    sick = True              pos : neg    =      2.1 : 1.0\n",
      "                 brosnan = True              neg : pos    =      1.9 : 1.0\n",
      "                  hidden = True              pos : neg    =      1.8 : 1.0\n",
      "                absolute = True              pos : neg    =      1.8 : 1.0\n",
      "                     hey = True              neg : pos    =      1.8 : 1.0\n",
      "               ourselves = True              neg : pos    =      1.8 : 1.0\n",
      "                 costume = True              neg : pos    =      1.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#NAIVE BAYES \n",
    "\n",
    "classifier=nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "\n",
    "print(\"original_accuracy by naive_bayes:\",nltk.classify.accuracy(classifier,test_set)*100)\n",
    "\n",
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb_accuracy: 14.006024096385541\n"
     ]
    }
   ],
   "source": [
    "#MNB CLASSIFIER\n",
    "\n",
    "MNB_classifier=SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"mnb_accuracy:\",nltk.classify.accuracy(MNB_classifier,test_set)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn_accuracy: 14.307228915662652\n"
     ]
    }
   ],
   "source": [
    "#USING bernoulliCLASSSIFIER\n",
    "\n",
    "BN_classifier=SklearnClassifier(BernoulliNB())\n",
    "BN_classifier.train(training_set)\n",
    "print(\"bn_accuracy:\",nltk.classify.accuracy(BN_classifier,test_set)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chiranjeev/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression accuracy: 13.102409638554215\n"
     ]
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "\n",
    "logistic_regression=SklearnClassifier(LogisticRegression())\n",
    "logistic_regression.train(training_set)\n",
    "print(\"logistic_regression accuracy:\",nltk.classify.accuracy(logistic_regression,test_set)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chiranjeev/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier accuracy: 29.819277108433734\n"
     ]
    }
   ],
   "source": [
    "#SGD CLASSIFIER\n",
    "SGDClassifier=SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier.train(training_set)\n",
    "print(\"SGDClassifier accuracy:\",nltk.classify.accuracy(SGDClassifier,test_set)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chiranjeev/.local/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC_Classifier accuracy: 49.39759036144578\n"
     ]
    }
   ],
   "source": [
    "#SVC CLASSIFIER\n",
    "SVC_Classifier=SklearnClassifier(SVC())\n",
    "SVC_Classifier.train(training_set)\n",
    "print(\"SVC_Classifier accuracy:\",nltk.classify.accuracy(SVC_Classifier,test_set)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_Classifier accuracy: 12.198795180722891\n"
     ]
    }
   ],
   "source": [
    "#LINEAR CLASSIFIER\n",
    "\n",
    "LinearSVC_Classifier=SklearnClassifier(LinearSVC())\n",
    "LinearSVC_Classifier.train(training_set)\n",
    "print(\"LinearSVC_Classifier accuracy:\",nltk.classify.accuracy(LinearSVC_Classifier,test_set)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NuSVC_Classifier accuracy: 60.8433734939759\n"
     ]
    }
   ],
   "source": [
    "#NUSVC CLASSIFIER\n",
    "NuSVC_Classifier=SklearnClassifier(NuSVC())\n",
    "NuSVC_Classifier.train(training_set)\n",
    "print(\"NuSVC_Classifier accuracy:\",nltk.classify.accuracy(NuSVC_Classifier,test_set)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voted_classifier accuracy: 48.795180722891565\n",
      "5\n",
      "classfication: neg 100.0\n",
      "5\n",
      "classfication: pos 100.0\n",
      "4\n",
      "classfication: pos 80.0\n",
      "5\n",
      "classfication: neg 100.0\n"
     ]
    }
   ],
   "source": [
    "voted_classifier=VoteClassifier(MNB_classifier,BN_classifier,logistic_regression,LinearSVC_Classifier,NuSVC_Classifier)#,SGDClassifier,classifier,SVC_Classifier)\n",
    "\n",
    "print(\"voted_classifier accuracy:\",nltk.classify.accuracy(voted_classifier,test_set)*100)\n",
    "print(\"classfication:\",voted_classifier.classify(test_set[0][0]),voted_classifier.confidence(test_set[0][0])*100)\n",
    "print(\"classfication:\",voted_classifier.classify(test_set[1][0]),voted_classifier.confidence(test_set[1][0])*100)\n",
    "print(\"classfication:\",voted_classifier.classify(test_set[4][0]),voted_classifier.confidence(test_set[4][0])*100)\n",
    "print(\"classfication:\",voted_classifier.classify(test_set[3][0]),voted_classifier.confidence(test_set[3][0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
